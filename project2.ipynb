{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data exploration\n",
    "\n",
    "### Frequency\n",
    "\n",
    "Frequency is the measurement of the speed of vibration in sound waves, which determines the pitch of the sound. It is the number of wave cycles that occur in one second, measured in Hertz (Hz).\n",
    "\n",
    "### Median frequency\n",
    "\n",
    "Is the middle value of a sorted dataset.\n",
    "\n",
    "### Output label\n",
    "\n",
    "The output label is used to identify which gender the voice belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"voice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['label'] == 'male', 'label'] = 1\n",
    "df.loc[df['label'] == 'female', 'label'] = 0\n",
    "\n",
    "y = np.array(df['label'],dtype=int)\n",
    "X = np.array(df.iloc[:, 0:20],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2851, 20) (317, 20) (2851,) (317,)\n",
      "(2852, 20) (316, 20) (2852,) (316,)\n",
      "(2852, 20) (316, 20) (2852,) (316,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)   \n",
    "    \n",
    "#folds = [(X[train_index],X[test_index],y[train_index],y[test_index])for train_index, test_index in kf.split(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pipeline1 = make_pipeline(StandardScaler(), LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial'))\n",
    "#Pipeline([('clf', LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial'))])\n",
    "pipeline2 = make_pipeline(StandardScaler(), svm.SVC(gamma='scale'))\n",
    "#Pipeline([('SVC', svm.SVC(gamma='scale'))])\n",
    "pipeline3 = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=0))\n",
    "#Pipeline([('dtc', DecisionTreeClassifier(random_state=0))])\n",
    "pipeline4 = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n",
    "#Pipeline([('KNeigh', KNeighborsClassifier(n_neighbors=3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression\n",
    "\n",
    "    I think this model will perform well, because the dependtent variable is binary(male/female). \n",
    "    \n",
    "    \n",
    "- Support Vector Machine classifier / k-Nearest Neighbors classifier\n",
    "\n",
    "    I think this or the k-Nearest Neighbors classifier will perform bettter than the Decision Tree classifier and almost as good as the Logistic regression.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Decision Tree classifier\n",
    "\n",
    "    Compared to the other classifiers, we think this we perform the worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Score: [0.91194969 0.96855346 0.96855346 0.97484277 0.96202532 0.98734177\n",
      " 0.98417722 0.9778481  0.94620253 0.98417722]\n",
      "Mean:  0.9665671522967918\n",
      "---------------------\n",
      "Support vector\n",
      "Score: [0.93081761 0.95597484 0.96855346 0.9591195  0.96835443 0.99683544\n",
      " 0.98734177 0.98101266 0.91455696 0.99367089]\n",
      "Mean:  0.9656237560703765\n",
      "---------------------\n",
      "Decision Tree\n",
      "Score: [0.89622642 0.91194969 0.97484277 0.94654088 0.96518987 0.9778481\n",
      " 0.99050633 0.98101266 0.90506329 0.94936709]\n",
      "Mean:  0.9498547090199825\n",
      "---------------------\n",
      "K-neighbours\n",
      "Score: [0.90566038 0.93710692 0.9591195  0.92767296 0.95886076 0.98734177\n",
      " 0.98734177 0.98417722 0.89873418 0.9778481 ]\n",
      "Mean:  0.9523863545896027\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [pipeline1,pipeline2,pipeline3,pipeline4]\n",
    "model_name = ['Logistic regression','Support vector','Decision Tree','K-neighbours']\n",
    "for index,model in enumerate(models):\n",
    "    print(model_name[index])\n",
    "    scores = cross_val_score(model,X, y, cv=10)\n",
    "    print('Score:', scores)\n",
    "    print('Mean: ',sum(scores)/len(scores))\n",
    "    print('---------------------')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand in\n",
    "\n",
    "The score shows how often the classifer predicts the value correctly. The score is a value between 0 and 1.\n",
    "\n",
    "The scores are different due to the fact that the test and traning data changes K times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Model optimisation: scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already used StandardScaler in part 4. Because running the code without Scarler produced some warnings and to fix these warnings we needed to normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is used to change data so it fits with some boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean scores : \n",
    "    \n",
    "    Logistic regression - 0.9665671522967918\n",
    "    Support vector - 0.9656237560703765\n",
    "    Decision Tree - 0.9498547090199825\n",
    "    K-neighbours - 0.9504975718493751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preditions matched the results quit well. Decision Tree was the worst and Logistic regression classifier was the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9441983122362869\n",
      "2 0.9476833054693099\n",
      "3 0.9504975718493751\n",
      "4 0.9527207228723829\n",
      "5 0.9523863545896027\n",
      "6 0.9520838309051827\n",
      "7 0.9501811161531727\n",
      "8 0.9520758697555929\n",
      "9 0.9508080566833852\n",
      "10 0.9514449486505852\n",
      "Best value for k :  4\n"
     ]
    }
   ],
   "source": [
    "rate = 0;\n",
    "best_i = 0\n",
    "for i in range(1,11):\n",
    "    model = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=i))\n",
    "    scores = cross_val_score(model,X, y, cv=10)\n",
    "    avg_score = sum(scores)/len(scores)\n",
    "    print(i,avg_score)\n",
    "    if avg_score > rate:\n",
    "        rate = avg_score\n",
    "        best_i = i\n",
    "print('Best value for k : ',best_i)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
